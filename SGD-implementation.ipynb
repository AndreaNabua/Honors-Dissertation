{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c08d5c2",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "322683fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-23 17:14:52.528095: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-23 17:14:54.579026: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-23 17:14:54.579943: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-23 17:14:54.579954: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "import string\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from matplotlib import rc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter, defaultdict\n",
    "from sklearn.metrics import accuracy_score, average_precision_score\n",
    "import matplotlib.ticker as ticker\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00caf73b",
   "metadata": {},
   "source": [
    "# Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bbb5470",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['carnitine', 'GABA', 'delta-aminolevulinic acid', 'leucovorin', 'PGE2',\n",
       "       'prostacyclin', 'acetate', 'acetylcholine', 'adenosine', 'galactose',\n",
       "       ...\n",
       "       'rifapentine', 'sucralfate', 'cefdinir', 'ivermectin', 'rifaximin',\n",
       "       'pimecrolimus', 'auranofin', 'cefditoren', 'nitroprusside',\n",
       "       'gold sodium thiomalate'],\n",
       "      dtype='object', length=888)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pauwel = pd.read_csv(\"pauwel-dataset.txt\", sep='\\t', header=0)\n",
    "pauwel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d8112a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abdominal.cramps</th>\n",
       "      <th>abdominal.distention</th>\n",
       "      <th>abdominal.pain</th>\n",
       "      <th>malformations</th>\n",
       "      <th>spontaneous.abortion</th>\n",
       "      <th>missed.abortion</th>\n",
       "      <th>abscess</th>\n",
       "      <th>acanthosis.nigricans</th>\n",
       "      <th>acidosis</th>\n",
       "      <th>renal.tubular.acidosis</th>\n",
       "      <th>...</th>\n",
       "      <th>vitamin.deficiency</th>\n",
       "      <th>drug.dependence</th>\n",
       "      <th>diverticulosis</th>\n",
       "      <th>prostatic.hypertrophy</th>\n",
       "      <th>allergic.reaction</th>\n",
       "      <th>dysphonia</th>\n",
       "      <th>eosinophilic.pneumonia</th>\n",
       "      <th>retinal.vein.thrombosis</th>\n",
       "      <th>renal.insufficiency</th>\n",
       "      <th>glioblastoma.multiforme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6398525</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6398970</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6447131</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6918453</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11947681</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>658 rows Ã— 1339 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          abdominal.cramps  abdominal.distention  abdominal.pain  \\\n",
       "85                       1                     0               0   \n",
       "119                      0                     0               0   \n",
       "137                      0                     0               0   \n",
       "143                      0                     0               0   \n",
       "158                      0                     0               1   \n",
       "...                    ...                   ...             ...   \n",
       "6398525                  0                     0               0   \n",
       "6398970                  0                     0               1   \n",
       "6447131                  0                     0               1   \n",
       "6918453                  0                     0               1   \n",
       "11947681                 0                     0               1   \n",
       "\n",
       "          malformations  spontaneous.abortion  missed.abortion  abscess  \\\n",
       "85                    0                     0                0        0   \n",
       "119                   0                     0                0        0   \n",
       "137                   0                     0                0        0   \n",
       "143                   0                     0                0        0   \n",
       "158                   0                     0                0        0   \n",
       "...                 ...                   ...              ...      ...   \n",
       "6398525               0                     0                0        0   \n",
       "6398970               0                     0                0        0   \n",
       "6447131               0                     0                0        0   \n",
       "6918453               0                     0                0        0   \n",
       "11947681              0                     0                0        0   \n",
       "\n",
       "          acanthosis.nigricans  acidosis  renal.tubular.acidosis  ...  \\\n",
       "85                           0         0                       0  ...   \n",
       "119                          0         0                       0  ...   \n",
       "137                          0         0                       0  ...   \n",
       "143                          0         0                       0  ...   \n",
       "158                          0         1                       0  ...   \n",
       "...                        ...       ...                     ...  ...   \n",
       "6398525                      0         0                       0  ...   \n",
       "6398970                      0         0                       0  ...   \n",
       "6447131                      0         0                       0  ...   \n",
       "6918453                      0         0                       0  ...   \n",
       "11947681                     0         0                       0  ...   \n",
       "\n",
       "          vitamin.deficiency  drug.dependence  diverticulosis  \\\n",
       "85                         0                1               0   \n",
       "119                        0                0               0   \n",
       "137                        0                0               0   \n",
       "143                        0                0               0   \n",
       "158                        0                0               0   \n",
       "...                      ...              ...             ...   \n",
       "6398525                    0                0               0   \n",
       "6398970                    0                0               0   \n",
       "6447131                    0                0               0   \n",
       "6918453                    0                0               0   \n",
       "11947681                   0                0               0   \n",
       "\n",
       "          prostatic.hypertrophy  allergic.reaction  dysphonia  \\\n",
       "85                            0                  1          0   \n",
       "119                           0                  0          0   \n",
       "137                           0                  0          0   \n",
       "143                           0                  0          0   \n",
       "158                           0                  0          0   \n",
       "...                         ...                ...        ...   \n",
       "6398525                       0                  0          0   \n",
       "6398970                       0                  1          0   \n",
       "6447131                       0                  1          0   \n",
       "6918453                       0                  0          0   \n",
       "11947681                      0                  0          0   \n",
       "\n",
       "          eosinophilic.pneumonia  retinal.vein.thrombosis  \\\n",
       "85                             0                        0   \n",
       "119                            0                        0   \n",
       "137                            0                        0   \n",
       "143                            0                        0   \n",
       "158                            0                        0   \n",
       "...                          ...                      ...   \n",
       "6398525                        0                        0   \n",
       "6398970                        1                        0   \n",
       "6447131                        0                        0   \n",
       "6918453                        0                        0   \n",
       "11947681                       0                        0   \n",
       "\n",
       "          renal.insufficiency  glioblastoma.multiforme  \n",
       "85                          0                        0  \n",
       "119                         0                        0  \n",
       "137                         0                        0  \n",
       "143                         0                        0  \n",
       "158                         0                        0  \n",
       "...                       ...                      ...  \n",
       "6398525                     0                        0  \n",
       "6398970                     0                        0  \n",
       "6447131                     0                        0  \n",
       "6918453                     0                        0  \n",
       "11947681                    0                        0  \n",
       "\n",
       "[658 rows x 1339 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mizutani = pd.read_csv(\"mizutani-dataset.txt\", sep='\\t', header=0)\n",
    "mizutani # drug names are coded with pubchem ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f19af2cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Check number of missing values\n",
    "new_pauwel = pauwel.fillna(999).values\n",
    "num_missing_pauwel = np.argwhere(new_pauwel == 999)\n",
    "print(len(num_missing_pauwel))\n",
    "\n",
    "new_mizutani = mizutani.fillna(999).values\n",
    "num_missing_mizutani = np.argwhere(new_mizutani == 999)\n",
    "print(len(num_missing_mizutani))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "260c4778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.97%\n"
     ]
    }
   ],
   "source": [
    "# Check the density of the pauwel dataset\n",
    "density = float(len(np.nonzero(pauwel.to_numpy())[0]))\n",
    "density /= (pauwel.shape[0]*pauwel.shape[1])\n",
    "density *= 100\n",
    "print('{:.2f}%'.format(density))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9eabe3db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.57%\n"
     ]
    }
   ],
   "source": [
    "# Check the density of the mizutani dataset\n",
    "density = float(len(np.nonzero(mizutani.to_numpy())[0]))\n",
    "density /= (mizutani.shape[0]*mizutani.shape[1])\n",
    "density *= 100\n",
    "print('{:.2f}%'.format(density))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735c2959",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b835ce19",
   "metadata": {},
   "source": [
    "## Model Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "625d317b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD_Recommender:\n",
    "    \n",
    "    def __init__(self, k, lmbda, n_iter=350, learn_rate=0.005, tolerance=1e-04):\n",
    "        \"\"\"Set the parameters for SGD\"\"\"\n",
    "        \n",
    "        self.k=k\n",
    "        self.lmbda=lmbda\n",
    "        self.n_iter=n_iter\n",
    "        self.learn_rate=learn_rate\n",
    "        self.tolerance=tolerance\n",
    "        \n",
    "    def predictions(self, U: np.ndarray, V: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Return dot product of the matrices U and V.\"\"\"\n",
    "        \n",
    "        return np.dot(U, V.T)\n",
    "    \n",
    "    def check_convergence(self, U_old: np.ndarray, U_curr: np.ndarray, V_old: np.ndarray, V_curr: np.ndarray) -> bool:\n",
    "        \"\"\"Check if matrices have reached convergence.\"\"\"\n",
    "        \n",
    "        # subtract old and current matrices and see if each value in result matrix is less than tolerance \n",
    "        U_converged = np.all(np.abs(np.subtract(U_old,U_curr)) <= self.tolerance)\n",
    "        V_converged = np.all(np.abs(np.subtract(V_old,V_curr)) <= self.tolerance)\n",
    "        return U_converged and V_converged\n",
    "        \n",
    "    def fit(self, train: pd.DataFrame, dataset: pd.DataFrame) -> None:\n",
    "        \"\"\"Train the SGD model.\n",
    "        \n",
    "        Args:\n",
    "            train (pd.DataFrame): The training set\n",
    "            dataset (pd.DataFrame): The dataset\n",
    "        Returns: \n",
    "            None        \n",
    "        \"\"\"     \n",
    "        \n",
    "        m, n = dataset.shape\n",
    "        \n",
    "        # Initialize the low rank matrices U and V with values from the normal distribution N(0,0.01)\n",
    "        mu, sigma = 0, 0.1\n",
    "        self.U = np.random.normal(loc=mu, scale=sigma, size=(m, self.k))\n",
    "        self.V = np.random.normal(loc=mu, scale=sigma, size=(n, self.k))\n",
    "        \n",
    "        # Get the indices of known drug-se associations in the training set from the dataset\n",
    "        drugs, side_fx = train.values.nonzero()\n",
    "        drug_names = train.index[drugs]\n",
    "        side_fx_names = train.columns[side_fx]\n",
    "        drug_index = [dataset.index.get_loc(x) for x in drug_names]\n",
    "        side_fx_index = [dataset.columns.get_loc(x) for x in side_fx_names]\n",
    "        \n",
    "        drug_se = list(zip(drug_index, side_fx_index))\n",
    "        rng = np.random.default_rng()\n",
    "        \n",
    "        # Start of training\n",
    "        for epoch in range(self.n_iter):\n",
    "            rng.shuffle(drug_se) # Shuffle in place\n",
    "            U_old = self.U.copy()\n",
    "            V_old = self.V.copy()\n",
    "            \n",
    "            for (drug, se) in drug_se:\n",
    "                error = train[drug,se]-self.predictions(self.U[drug,:], self.V[se,:])\n",
    "                temp_u = self.U[drug,:] + self.learn_rate(error*self.V[se,:] - self.lmbda*self.U[drug,:])\n",
    "                temp_v = self.V[se,:] + self.learn_rate(error*self.U[se,:] - self.lmbda*self.V[se,:])\n",
    "                self.U[drug,:] = temp_u \n",
    "                self.V[se,:] = temp_v\n",
    "            \n",
    "            if self.check_convergence(U_old, self.U, V_old, self.V):\n",
    "                break\n",
    "            \n",
    "    def predict(self) -> np.ndarray:\n",
    "        \"\"\"Predict the entire drug-side effect matrix values.\"\"\"\n",
    "        \n",
    "        return self.predictions(self.U, self.V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b53a389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def five_fold_split(dataset):\n",
    "#     \"\"\"\n",
    "#     Splits dataset into 5 equal parts\n",
    "#     Input: Dataframe\n",
    "#     \"\"\"\n",
    "#     np.random.shuffle(dataset)\n",
    "#     fold_size = dataset.shape[0]//5\n",
    "    \n",
    "#     a = dataset.iloc[0:fold_size]\n",
    "#     b = dataset.iloc[fold_size:2*fold_size]\n",
    "#     c = dataset.iloc[2*fold_size:3*fold_size]\n",
    "#     d = dataset.iloc[3*fold_size:4*fold_size]\n",
    "#     e = dataset.iloc[4*fold_size:5*fold_size]\n",
    "    \n",
    "#     return a,b,c,d,e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "abe037fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val_5(dataset: pd.DataFrame, lmbda: float|int, k: int) -> np.ndarray:\n",
    "    \"\"\"Perform 5 fold CV, given regularization term (lambda) and number of latent features (k).\n",
    "    \n",
    "    Args:\n",
    "        dataset (pd.DataFrame): The dataset\n",
    "        lmbda (float): The regularization term\n",
    "        k (int): Number of latent features\n",
    "    Returns:\n",
    "        np.ndarray: Array of length 6 containing AUPR values of the 5 folds and the average value.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    np.random.shuffle(dataset)\n",
    "    fold_size = dataset.shape[0]//5\n",
    "    \n",
    "    # Specify the test sets of each fold\n",
    "    a = dataset.iloc[0:fold_size]\n",
    "    b = dataset.iloc[fold_size:2*fold_size]\n",
    "    c = dataset.iloc[2*fold_size:3*fold_size]\n",
    "    d = dataset.iloc[3*fold_size:4*fold_size]\n",
    "    e = dataset.iloc[4*fold_size:5*fold_size]\n",
    "    \n",
    "    # Create a model for each fold\n",
    "    model_a = SGD_recommender(k=k, lmbda=lmbda)\n",
    "    model_b = SGD_recommender(k=k, lmbda=lmbda)\n",
    "    model_c = SGD_recommender(k=k, lmbda=lmbda)\n",
    "    model_d = SGD_recommender(k=k, lmbda=lmbda)\n",
    "    model_e = SGD_recommender(k=k, lmbda=lmbda)\n",
    "    \n",
    "    \n",
    "    # model a\n",
    "    train_a = dataset.drop(a.index)\n",
    "    model_a.fit(train_a, dataset)\n",
    "    pred = pd.DataFrame(model_a.predict(), index=dataset.index, columns=dataset.columns)\n",
    "    aupr_a = get_aupr(truth=a.values, predictions=pred.iloc[0:fold_size].values)\n",
    "    \n",
    "    # model b\n",
    "    train_b = dataset.drop(b.index)\n",
    "    model_b.fit(train_b, dataset)\n",
    "    pred = pd.DataFrame(model_b.predict(), index=dataset.index, columns=dataset.columns)\n",
    "    aupr_b = get_aupr(truth=b.values, predictions=pred.iloc[fold_size:2*fold_size].values)\n",
    "    \n",
    "    # model c\n",
    "    train_c = dataset.drop(c.index)\n",
    "    model_c.fit(train_c, dataset)\n",
    "    pred = pd.DataFrame(model_c.predict(), index=dataset.index, columns=dataset.columns)\n",
    "    aupr_c = get_aupr(truth=c.values, predictions=pred.iloc[2*fold_size:3*fold_size].values)\n",
    "    \n",
    "    # model d\n",
    "    train_d = dataset.drop(d.index)\n",
    "    model_d.fit(train_d, dataset)\n",
    "    pred = pd.DataFrame(model_d.predict(), index=dataset.index, columns=dataset.columns)\n",
    "    aupr_d = get_aupr(truth=d.values, predictions=pred.iloc[3*fold_size:4*fold_size].values)\n",
    "    \n",
    "    # model e\n",
    "    train_e = dataset.drop(e.index)\n",
    "    model_e.fit(train_e, dataset)\n",
    "    pred = pd.DataFrame(model_e.predict(), index=dataset.index, columns=dataset.columns)\n",
    "    aupr_e = get_aupr(truth=e.values, predictions=pred.iloc[4*fold_size:5*fold_size].values)\n",
    "    \n",
    "    mean = np.mean([aupr_a, aupr_b, aupr_c, aupr_d, aupr_e])\n",
    "    return np.array([aupr_a, aupr_b, aupr_c, aupr_d, aupr_e, mean])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58bfbf16",
   "metadata": {},
   "source": [
    "## Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5db55757",
   "metadata": {},
   "outputs": [],
   "source": [
    "def param_selection(dataset: pd.Dataframe) -> dict:\n",
    "    \"\"\"Find the optimal set of parameters for the SGD model.\"\"\"\n",
    "    \n",
    "    k_values = [1,5,10,15,20,25,30,35,40,50,100]\n",
    "    lmda_values = [0.1,1,5,10,15,20]\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # Do 5 fold CV for each possible combination of lambda and k\n",
    "    for (k,lmbda) in product(k_values, lmda_values):\n",
    "        res = cross_val_5(dataset=dataset, lmbda=lmbda, k=k)\n",
    "        results[(k,lmbda)] = res\n",
    "    \n",
    "    return results\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ca5104",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_optimal_params(dataset: pd.DataFrame, lmbda: float|int, k: int) -> dict:\n",
    "    \"\"\"Do 20 runs of 5 fold CV.\"\"\"\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for run in range(20)\n",
    "        res = cross_val_5(dataset=dataset, lmbda=lmbda, k=k)\n",
    "        results[run] = res\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d242aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aupr(truth: np.ndarray, predictions: np.ndarray) -> float:\n",
    "    \"\"\"Get the area under the precision-recall curve.\"\"\"\n",
    "    \n",
    "    max_value = predictions.max()\n",
    "    min_value = predictions.min()\n",
    "    # Create an array of 99 representing the thresholds\n",
    "    threshold = min_value + (max_value-min_value)*(np.arange(1,100,1)/100)\n",
    "    \n",
    "    tn = np.zeros((threshold.size, 1))\n",
    "    tp = np.zeros((threshold.size, 1))\n",
    "    fn = np.zeros((threshold.size, 1))\n",
    "    tp = np.zeros((threshold.size, 1))\n",
    "    \n",
    "    # Calculate the tp, tn, fp, fn for every threshold.\n",
    "    for index in range(99):\n",
    "        tp[index,0] = np.logical_and(predictions>=threshold[index], truth==1).sum()\n",
    "        tn[index,0] = np.logical_and(predictions<threshold[index], truth==0).sum()\n",
    "        fp[index,0] = np.logical_and(predictions>=threshold[index], truth==0).sum()\n",
    "        fn[index,0] = np.logical_and(predictions<threshold[index], truth==1).sum()\n",
    "    \n",
    "    # Calculate the area under the precision-recall curve\n",
    "    recall = tp/(tp+fn)\n",
    "    prec = tp/(tp+fp)\n",
    "    \n",
    "    x = recall.copy()\n",
    "    y = prec.copy()\n",
    "    \n",
    "    sorted_index = x.argsort()\n",
    "    x = x[sorted_index]\n",
    "    y = y[sorted_index]\n",
    "\n",
    "    # Note that Zhang implementation sets the first values for x and y as 0 and 1 respectively\n",
    "    x[0][0] = 0\n",
    "    y[0][0] = 1\n",
    "#     x = np.insert(x, 0, 0, 0)\n",
    "#     y = np.insert(y, 0, 1, 0)\n",
    "    # x and y now have 100 values, not 99, causing no errors in trapezoidal rule calculation (indexoutofbound)\n",
    "    x = np.append(x, [[1]], 0)\n",
    "    y = np.append(y, [[0]], 0)\n",
    "\n",
    "    \n",
    "    # Calculate the area using the trapezoidal rule: (b-a)*0.5*(f(b)+f(a))\n",
    "    area = 0\n",
    "    area = 0.5*x[0][0]*(1+y[0][0]) # still 0\n",
    "    for idx in range(99):\n",
    "        area += (x[idx+1][0]-x[idx][0])*0.5*(y[idx][0]+ y[idx+1][0])\n",
    "    \n",
    "    return area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f29f153b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_aupr(truth: np.ndarray, predictions: np.ndarray) -> float:\n",
    "    \"\"\"Get the AUPR.\"\"\"\n",
    "    \n",
    "    return average_precision_score(truth.flatten(), predictions.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba53c0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def auroc(truth: np.ndarray, predictions: np.ndarray) -> float:\n",
    "    \"\"\"Get the area under the ROC curve.\"\"\"\n",
    "    \n",
    "    max_value = predictions.max()\n",
    "    min_value = predictions.min()\n",
    "    # Create an array of 99 representing the thresholds\n",
    "    threshold = min_value + (max_value-min_value)*(np.arange(1,100,1)/100)\n",
    "    \n",
    "    tn = np.zeros((threshold.size, 1))\n",
    "    tp = np.zeros((threshold.size, 1))\n",
    "    fn = np.zeros((threshold.size, 1))\n",
    "    tp = np.zeros((threshold.size, 1))\n",
    "    \n",
    "    # Calculate the tp, tn, fp, fn for every threshold.\n",
    "    for index in range(99):\n",
    "        tp[index,0] = np.logical_and(predictions>=threshold[index], truth==1).sum()\n",
    "        tn[index,0] = np.logical_and(predictions<threshold[index], truth==0).sum()\n",
    "        fp[index,0] = np.logical_and(predictions>=threshold[index], truth==0).sum()\n",
    "        fn[index,0] = np.logical_and(predictions<threshold[index], truth==1).sum()\n",
    "    \n",
    "    # Calculate the area under the precision-recall curve\n",
    "    sn = tp/(tp+fn)\n",
    "    sp = tn/(tn+fp)\n",
    "    x = 1 - sp\n",
    "    y = sn.copy()\n",
    "    \n",
    "    # Zhang sorted twice - I think it's redundant\n",
    "#     sorted_index = x.argsort()\n",
    "#     x = x[sorted_index]\n",
    "#     y = y[sorted_index]\n",
    "\n",
    "    sorted_index = y.argsort()\n",
    "    y = y[sorted_index]\n",
    "    x = x[sorted_index]\n",
    "\n",
    "    # x and y now have 100 values, not 99, causing no errors in trapezoidal rule calculation (indexoutofbound)\n",
    "    x = np.append(x, [[1]], 0)\n",
    "    y = np.append(y, [[1]], 0)\n",
    "\n",
    "    \n",
    "    # Calculate the area using the trapezoidal rule: (b-a)*0.5*(f(b)+f(a))\n",
    "    area = 0\n",
    "    area = 0.5*x[0][0]*(y[0][0]) # still 0\n",
    "    for idx in range(99):\n",
    "        area += (x[idx+1][0]-x[idx][0])*0.5*(y[idx][0]+ y[idx+1][0])\n",
    "    \n",
    "    return area"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d517ef2",
   "metadata": {},
   "source": [
    "## Running Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426760cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
